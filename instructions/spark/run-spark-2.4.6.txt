
cd $SPARK_HOME

####### RUN LOCALLY ###############

./bin/spark-submit \
  --class org.apache.spark.examples.SparkPi \
  --master local[2] \
  examples/jars/spark-examples_2.11-2.4.6.jar \
  10

./bin/spark-submit \
  --class org.apache.spark.examples.JavaWordCount \
  --master local[2] \
  examples/jars/spark-examples_2.11-2.4.6.jar \
  NOTICE

./bin/spark-submit \
  --class org.apache.spark.examples.JavaWordCount \
  --master local[2] \
  examples/jars/spark-examples_2.11-2.4.6.jar \
  hdfs://localhost:9000/path/to/file


####### RUN ON STANDALONE ###############

./bin/spark-submit \
  --class org.apache.spark.examples.SparkPi \
  --master spark://localhost:7077 \
  examples/jars/spark-examples_2.11-2.4.6.jar \
  10

./bin/spark-submit \
  --class org.apache.spark.examples.JavaWordCount \
  --master spark://localhost:7077 \
  examples/jars/spark-examples_2.11-2.4.6.jar \
  hdfs://localhost:9000/path/to/file


####### RUN ON YARN ###############

# For better performance, upload all $SPARK_HOME/jars on HDFS
# and specify the location in spark.yarn.jars in conf/spark-defaults.conf
# Example:
$HADOOP_HOME/bin/hdfs dfs -mkdir -p /user/hero/spark/share
$HADOOP_HOME/bin/hdfs dfs -put $SPARK_HOME/jars /user/hero/spark/share/.

spark.yarn.jars    hdfs://localhost:9000/user/hero/spark/share/jars/*.jar


./bin/spark-submit \
  --class org.apache.spark.examples.SparkPi \
  --master yarn \
  --deploy-mode cluster \
  examples/jars/spark-examples_2.11-2.4.6.jar \
  10

./bin/spark-submit \
  --class org.apache.spark.examples.JavaWordCount \
  --master yarn \
  --deploy-mode cluster \
  examples/jars/spark-examples_2.11-2.4.6.jar \
  hdfs://localhost:9000/path/to/file


# To enable dynamic allocation of executors in Spark using Yarn,
# you need to perform the following:
1. Copy spark-2.4.6/dist/yarn/spark-2.4.6-yarn-shuffle.jar
into hadoop_deployment_dir/share/hadoop/yarn

2. Add the following entries in spark-defaults.conf:
spark.shuffle.service.enabled    true
spark.dynamicAllocation.enabled  true
spark.dynamicAllocation.minExecutors  0
spark.dynamicAllocation.maxExecutors  1
spark.executor.instances   0

3. Modify/Add the following entries in yarn-site.xml
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>spark_shuffle,mapreduce_shuffle</value>
    <description>shuffle service that needs to be set for Map Reduce to run </description>
  </property>

  <property>
    <name>yarn.nodemanager.aux-services.spark_shuffle.class</name>
    <value>org.apache.spark.network.yarn.YarnShuffleService</value>
  </property>

4. Restart yarn



